# Ressources Requirements

## 1. A pod called rabbit is deployed. Identify the CPU requirements set on the Pod
```
controlplane ~ ➜  kubectl describe pod rabbit
Name:             rabbit
Namespace:        default
Priority:         0
Service Account:  default
Node:             controlplane/172.25.0.8
Start Time:       Wed, 26 Apr 2023 20:15:07 +0000
Labels:           <none>
Annotations:      <none>
Status:           Running
IP:               10.42.0.9
IPs:
  IP:  10.42.0.9
Containers:
  cpu-stress:
    Container ID:  containerd://c8faafd8124f6b1a8f1f1ed736c0f468fa245e325d4a3b09d545a6a10ddfb48b
    Image:         ubuntu
    Image ID:      docker.io/library/ubuntu@sha256:67211c14fa74f070d27cc59d69a7fa9aeff8e28ea118ef3babc295a0428a6d21
    Port:          <none>
    Host Port:     <none>
    Args:
      sleep
      1000
    State:          Waiting
      Reason:       CrashLoopBackOff
    Last State:     Terminated
      Reason:       StartError
      Message:      failed to create containerd task: failed to create shim task: OCI runtime create failed: runc create failed: unable to start container process: error during container init: error setting cgroup config for procHooks process: failed to write "200000": write /sys/fs/cgroup/cpu,cpuacct/kubepods/burstable/pod36e1aab2-00fa-4eb5-9bc6-c17b09a2318f/c8faafd8124f6b1a8f1f1ed736c0f468fa245e325d4a3b09d545a6a10ddfb48b/cpu.cfs_quota_us: invalid argument: unknown
      Exit Code:    128
      Started:      Thu, 01 Jan 1970 00:00:00 +0000
      Finished:     Wed, 26 Apr 2023 20:16:41 +0000
    Ready:          False
    Restart Count:  4
    Limits:
      cpu:  2
    Requests:
      cpu:        1
    Environment:  <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-mgqhj (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             False 
  ContainersReady   False 
  PodScheduled      True 
Volumes:
  kube-api-access-mgqhj:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   Burstable
Node-Selectors:              <none>
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type     Reason     Age                  From               Message
  ----     ------     ----                 ----               -------
  Normal   Scheduled  2m11s                default-scheduler  Successfully assigned default/rabbit to controlplane
  Normal   Pulled     2m7s                 kubelet            Successfully pulled image "ubuntu" in 4.301894917s (4.301924819s including waiting)
  Normal   Pulled     2m4s                 kubelet            Successfully pulled image "ubuntu" in 443.098438ms (443.115015ms including waiting)
  Normal   Pulled     108s                 kubelet            Successfully pulled image "ubuntu" in 448.737563ms (448.763404ms including waiting)
  Normal   Pulled     80s                  kubelet            Successfully pulled image "ubuntu" in 470.56089ms (470.582723ms including waiting)
  Normal   Created    80s (x4 over 2m7s)   kubelet            Created container cpu-stress
  Warning  Failed     80s (x4 over 2m5s)   kubelet            Error: failed to create containerd task: failed to create shim task: OCI runtime create failed: runc create failed: unable to start container process: error during container init: error setting cgroup config for procHooks process: failed to write "200000": write /sys/fs/cgroup/cpu,cpuacct/kubepods/burstable/pod36e1aab2-00fa-4eb5-9bc6-c17b09a2318f/cpu-stress/cpu.cfs_quota_us: invalid argument: unknown
  Warning  BackOff    52s (x7 over 2m3s)   kubelet            Back-off restarting failed container cpu-stress in pod rabbit_default(36e1aab2-00fa-4eb5-9bc6-c17b09a2318f)
  Normal   Pulling    38s (x5 over 2m11s)  kubelet            Pulling image "ubuntu"
  Normal   Pulled     38s                  kubelet            Successfully pulled image "ubuntu" in 496.36392ms (496.381881ms including waiting)
```
1

## 2. Delete the rabbit Pod.

Once deleted, wait for the pod to fully terminate.

```
controlplane ~ ✖ k delete pod rabbit
pod "rabbit" deleted
```

## 3. Another pod called elephant has been deployed in the default namespace. It fails to get to a running state. Inspect this pod and identify the Reason why it is not running.

````
controlplane ~ ➜  k describe pod elephant
Name:             elephant
Namespace:        default
Priority:         0
Service Account:  default
Node:             controlplane/172.25.0.8
Start Time:       Wed, 26 Apr 2023 20:19:57 +0000
Labels:           <none>
Annotations:      <none>
Status:           Running
IP:               10.42.0.10
IPs:
  IP:  10.42.0.10
Containers:
  mem-stress:
    Container ID:  containerd://337289851e6c45f14bf0e09b5fe057ad282d8b606f9f47a2d24b5071460f4897
    Image:         polinux/stress
    Image ID:      docker.io/polinux/stress@sha256:b6144f84f9c15dac80deb48d3a646b55c7043ab1d83ea0a697c09097aaad21aa
    Port:          <none>
    Host Port:     <none>
    Command:
      stress
    Args:
      --vm
      1
      --vm-bytes
      15M
      --vm-hang
      1
    State:          Waiting
      Reason:       CrashLoopBackOff
    Last State:     Terminated
      Reason:       OOMKilled
      Exit Code:    1
      Started:      Wed, 26 Apr 2023 20:20:51 +0000
      Finished:     Wed, 26 Apr 2023 20:20:51 +0000
    Ready:          False
    Restart Count:  3
    Limits:
      memory:  10Mi
    Requests:
      memory:     5Mi
    Environment:  <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-cpwc8 (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             False 
  ContainersReady   False 
  PodScheduled      True 
Volumes:
  kube-api-access-cpwc8:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   Burstable
Node-Selectors:              <none>
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type     Reason     Age                From               Message
  ----     ------     ----               ----               -------
  Normal   Scheduled  95s                default-scheduler  Successfully assigned default/elephant to controlplane
  Normal   Pulled     93s                kubelet            Successfully pulled image "polinux/stress" in 1.483641296s (1.483657559s including waiting)
  Normal   Pulled     91s                kubelet            Successfully pulled image "polinux/stress" in 660.668206ms (660.691951ms including waiting)
  Normal   Pulled     73s                kubelet            Successfully pulled image "polinux/stress" in 493.146915ms (493.179013ms including waiting)
  Normal   Pulling    42s (x4 over 94s)  kubelet            Pulling image "polinux/stress"
  Normal   Pulled     42s                kubelet            Successfully pulled image "polinux/stress" in 460.661825ms (460.680774ms including waiting)
  Normal   Created    42s (x4 over 93s)  kubelet            Created container mem-stress
  Normal   Started    41s (x4 over 92s)  kubelet            Started container mem-stress
  Warning  BackOff    1s (x8 over 89s)   kubelet            Back-off restarting failed container mem-stress in pod elephant_default(ea98385b-618e-4bae-9358-51dbb23f37d7)
````

OOMKilled: out of memory

## 4. The elephant pod runs a process that consumes 15Mi of memory. Increase the limit of the elephant pod to 20Mi.

Delete and recreate the pod if required. Do not modify anything other than the required fields.

- Pod Name: elephant
- Image Name: polinux/stress
- Memory Limit: 20Mi

```
controlplane ~ ➜  kubectl get pod elephant -o yaml > elephant.yaml

controlplane ~ ➜  k delete pod elephant
pod "elephant" deleted
controlplane ~ ➜  vi elephant.yaml
```