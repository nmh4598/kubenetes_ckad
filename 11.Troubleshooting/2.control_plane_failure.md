# Solution: Control Plane Failure

## 1. Fix the broken cluster

**Hint**: Step1. Check the status of services on the nodes.

Step2. Check the service logs using ``journalctl -u kubelet.``

Step3. If it's stopped then start the stopped services.

Alternatively, run the command:

``ssh node01 "service kubelet start"``

**Solution**: 

**Step1:** Check the status of the nodes:
```bash
controlplane:~> kubectl get nodes
NAME           STATUS     ROLES           AGE     VERSION
controlplane   Ready      control-plane   5m43s   v1.26.0
node01         NotReady   <none>          5m7s    v1.26.0

controlplane:~> 
```
Step 2: SSH to ``node01`` and check the status of the container runtime (``containerd``, in this case) and the ``kubelet ``service.
```bash
root@node01:~> systemctl status containerd
● containerd.service - containerd container runtime
     Loaded: loaded (/lib/systemd/system/containerd.service; enabled; vendor preset: enabled)
     Active: active (running) since Thu 2022-12-29 14:50:26 EST; 11min ago
       Docs: https://containerd.io
   Main PID: 1058 (containerd)
      Tasks: 65
     Memory: 181.2M
     CGroup: /system.slice/containerd.service

root@node01:~>

root@node01:~> systemctl status kubelet
● kubelet.service - kubelet: The Kubernetes Node Agent
     Loaded: loaded (/lib/systemd/system/kubelet.service; enabled; vendor preset: enabled)
    Drop-In: /etc/systemd/system/kubelet.service.d
             └─10-kubeadm.conf
     Active: inactive (dead) since Thu 2022-12-29 14:51:58 EST; 7min ago
       Docs: https://kubernetes.io/docs/home/
    Process: 2085 ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTR>
   Main PID: 2085 (code=exited, status=0/SUCCESS)
```

Since the ``kubelet`` is not running, attempt to start it by running the following command:

```bash
root@node01:~> systemctl start kubelet

root@node01:~> systemctl status kubelet
● kubelet.service - kubelet: The Kubernetes Node Agent
     Loaded: loaded (/lib/systemd/system/kubelet.service; enabled; vendor preset: enabled)
    Drop-In: /etc/systemd/system/kubelet.service.d
             └─10-kubeadm.conf
     Active: active (running) since Thu 2022-12-29 15:00:26 EST; 3s ago
       Docs: https://kubernetes.io/docs/home/
```

``node01`` should go back to ready state now.

Step1: Check the status of the nodes:
```bash
controlplane:~> kubectl get nodes
NAME           STATUS     ROLES           AGE     VERSION
controlplane   Ready      control-plane   5m43s   v1.26.0
node01         NotReady   <none>          5m7s    v1.26.0

controlplane:~> 
```
Step 2: SSH to ``node01`` and check the status of the container runtime (``containerd``, in this case) and the ``kubelet`` service.
```bash
root@node01:~> systemctl status containerd
● containerd.service - containerd container runtime
     Loaded: loaded (/lib/systemd/system/containerd.service; enabled; vendor preset: enabled)
     Active: active (running) since Thu 2022-12-29 14:50:26 EST; 11min ago
       Docs: https://containerd.io
   Main PID: 1058 (containerd)
      Tasks: 65
     Memory: 181.2M
     CGroup: /system.slice/containerd.service

root@node01:~>

root@node01:~> systemctl status kubelet
● kubelet.service - kubelet: The Kubernetes Node Agent
     Loaded: loaded (/lib/systemd/system/kubelet.service; enabled; vendor preset: enabled)
    Drop-In: /etc/systemd/system/kubelet.service.d
             └─10-kubeadm.conf
     Active: inactive (dead) since Thu 2022-12-29 14:51:58 EST; 7min ago
       Docs: https://kubernetes.io/docs/home/
    Process: 2085 ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTR>
   Main PID: 2085 (code=exited, status=0/SUCCESS)
```
Since the`` kubelet`` is not running, attempt to start it by running the following command:
```bash
root@node01:~> systemctl start kubelet

root@node01:~> systemctl status kubelet
● kubelet.service - kubelet: The Kubernetes Node Agent
     Loaded: loaded (/lib/systemd/system/kubelet.service; enabled; vendor preset: enabled)
    Drop-In: /etc/systemd/system/kubelet.service.d
             └─10-kubeadm.conf
     Active: active (running) since Thu 2022-12-29 15:00:26 EST; 3s ago
       Docs: https://kubernetes.io/docs/home/
```
``node01`` should go back to ready state now.

**Hand-ons**


## 2. systemctl status containerd

**Hint**:Inspect the logs using ``journalctl -u kubelet -f``. Fix the issue in the file.
`
**Solution**:

``kubelet`` has stopped running on ``node01`` again. Since this is a systemd managed system, we can check the ``kubelet`` log by running ``journalctl`` command. Here is a snippet showing the error with ``kubelet``:
```bash
root@node01:~# journalctl -u kubelet 
.
.
Dec 29 14:32:36 node01 kubelet[4670]: E1229 14:32:36.331403    4670 run.go:74] "command failed" err="failed to construct kubelet dependencies: unable to load client CA file /etc/kubernetes/pki/WRONG-CA-FILE.crt: open /etc/kubernetes/pki/WRONG-CA-FILE.crt: no such file or directory"
.
.
```
There appears to be a mistake path used for the CA certificate in the ``kubelet`` configuration. This can be corrected by updating the file ``/var/lib/kubelet/config.yaml``.

Once this is fixed, restart the ``kubelet ``service, (like we did in the previous question) and ``node01`` should return back to a working state.





## 3 The cluster is broken again. Investigate and fix the issue.

**Hint** : 
Check the kubelet.conf file at /etc/kubernetes/kubelet.conf.

**Solution**: 
Once again the ``kubelet ``service has stopped working. Checking the logs, we can see that this time, it is not able to reach the kube-apiserver.
```bash
root@node01:~# journalctl -u kubelet 
.
.
.
Dec 29 14:39:38 node01 kubelet[6005]: E1229 14:39:38.637930    6005 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://controlplane:6553/api/v1/nodes?fieldSelector=metadata.name%3Dnode01&limit=500&resourceVersion=0": dial tcp 10.33.28.7:6553: connect: connection refused
.
.
.
```
As we can clearly see, ``kubelet`` is trying to connect to the API server on the ``controlplane`` node on port ``6553``. This is incorrect.
To fix, correct the port on the ``kubeconfig`` file used by the ``kubelet``.
```bash
apiVersion: v1
clusters:
- cluster:
    certificate-authority-data:
    --REDACTED---
    server: https://controlplane:6443
```
Restart the ``kubelet`` service after this change.
```bash
systemctl restart kubelet
```

```bash

```

```bash

```

```bash

```

```bash

```

```bash
```