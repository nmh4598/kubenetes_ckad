# Core DNS 

## 1. Identify the DNS solution implemented in this cluster.

```bash
controlplane ~ ➜  kubectl get pods -n kube-system
NAME                                   READY   STATUS    RESTARTS   AGE
coredns-787d4945fb-46j4r               1/1     Running   0          3m8s
coredns-787d4945fb-qd274               1/1     Running   0          3m8s
etcd-controlplane                      1/1     Running   0          3m23s
kube-apiserver-controlplane            1/1     Running   0          3m22s
kube-controller-manager-controlplane   1/1     Running   0          3m19s
kube-proxy-c522h                       1/1     Running   0          3m8s
kube-scheduler-controlplane            1/1     Running   0          3m24s
```

coredns

## 2. How many pods of the DNS server are deployed?

Look for Desired count of coredns

2

## 3. What is the name of the service created for accessing CoreDNS?

```bash
controlplane ~ ➜  k get svc -n kube-system
NAME       TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)                  AGE
kube-dns   ClusterIP   10.96.0.10   <none>        53/UDP,53/TCP,9153/TCP   5m1s
```
kube-dns

## 4. What is the IP of the CoreDNS server that should be configured on PODs to resolve services?

10.96.0.10

## 5. Where is the configuration file located for configuring the CoreDNS service?

```bash
controlplane ~ ✖ k describe pod coredns-787d4945fb-46j4r  -n kube-system
Name:                 coredns-787d4945fb-46j4r
Namespace:            kube-system
Priority:             2000000000
Priority Class Name:  system-cluster-critical
Service Account:      coredns
Node:                 controlplane/192.27.106.3
Start Time:           Sun, 30 Apr 2023 10:19:05 -0400
Labels:               k8s-app=kube-dns
                      pod-template-hash=787d4945fb
Annotations:          <none>
Status:               Running
IP:                   10.244.0.2
IPs:
  IP:           10.244.0.2
Controlled By:  ReplicaSet/coredns-787d4945fb
Containers:
  coredns:
    Container ID:  containerd://15f9aeac22e09e14733078dfc8d6be37cc5e0d2ece5898ff27cc88502220d21f
    Image:         registry.k8s.io/coredns/coredns:v1.9.3
    Image ID:      registry.k8s.io/coredns/coredns@sha256:8e352a029d304ca7431c6507b56800636c321cb52289686a581ab70aaa8a2e2a
    Ports:         53/UDP, 53/TCP, 9153/TCP
    Host Ports:    0/UDP, 0/TCP, 0/TCP
    Args:
      -conf
      /etc/coredns/Corefile
```

```bash
controlplane ~ ➜  kubectl -n kube-system describe deployments.apps coredns | grep -A2 Args | grep Corefile
      /etc/coredns/Corefile
```
/etc/coredns/Corefile

## 6. How is the Corefile passed into the CoreDNS POD?

Corefile comes built-in with CoreDNS pod

pulled from git

Stored on the kube master

Configured as a ConfigMap object True 

```bash
controlplane ~ ➜  kubectl get cm -n kube-system
NAME                                 DATA   AGE
coredns                              1      9m13s
extension-apiserver-authentication   6      9m17s
kube-proxy                           2      9m13s
kube-root-ca.crt                     1      9m1s
kubeadm-config                       1      9m16s
kubelet-config                       1      9m16s
```

```bash
controlplane ~ ➜  k get pod coredns-787d4945fb-qd274 -n kube-system -o yaml
```

```yaml
---
    volumeMounts:
    - mountPath: /etc/coredns
      name: config-volume
      readOnly: true
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-542s4
      readOnly: true
---
---
  volumes:
  - configMap:
      defaultMode: 420
      items:
      - key: Corefile
        path: Corefile
      name: coredns
    name: config-volume
---
```
## 7. What is the name of the ConfigMap object created for Corefile?
     name: coredns

coredns

## 8. What is the root domain/zone configured for this kubernetes cluster?
```bash
controlplane ~ ➜  kubectl describe configmap coredns -n kube-system
Name:         coredns
Namespace:    kube-system
Labels:       <none>
Annotations:  <none>

Data
====
Corefile:
----
.:53 {
    errors
    health {
       lameduck 5s
    }
    ready
    kubernetes cluster.local in-addr.arpa ip6.arpa {
       pods insecure
       fallthrough in-addr.arpa ip6.arpa
       ttl 30
    }
    prometheus :9153
    forward . /etc/resolv.conf {
       max_concurrent 1000
    }
    cache 30
    loop
    reload
    loadbalance
}


BinaryData
====

Events:  <none>
```
Look for the entry after kubernetes.
This is root domain: cluster.local

## 9. We have deployed a set of PODs and Services in the ``default and payroll`` namespaces. Inspect them and go to the next question.
```bash
controlplane ~ ➜  k get pod
NAME                READY   STATUS    RESTARTS   AGE
hr                  1/1     Running   0          13m
simple-webapp-1     1/1     Running   0          13m
simple-webapp-122   1/1     Running   0          13m
test                1/1     Running   0          13m

controlplane ~ ➜  k get pod -n payroll
NAME   READY   STATUS    RESTARTS   AGE
web    1/1     Running   0          13m
```

## 10. What name can be used to access the ``hr`` web server from the ``test`` Application?

You can execute a curl command on the ``test`` pod to test. Alternatively, the test Application also has a UI. Access it using the tab at the top of your terminal named ``test-app``.
```bash
controlplane ~ ➜  k get svc
NAME           TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE
kubernetes     ClusterIP   10.96.0.1      <none>        443/TCP        16m
test-service   NodePort    10.98.139.37   <none>        80:30080/TCP   14m
web-service    ClusterIP   10.97.69.11    <none>        80/TCP         14m

controlplane ~ ➜  k describe service web-service
Name:              web-service
Namespace:         default
Labels:            <none>
Annotations:       <none>
Selector:          name=hr
Type:              ClusterIP
IP Family Policy:  SingleStack
IP Families:       IPv4
IP:                10.97.69.11
IPs:               10.97.69.11
Port:              <unset>  80/TCP
TargetPort:        80/TCP
Endpoints:         10.244.0.4:80
Session Affinity:  None
Events:            <none>
```
web-service

## 11. Which of the names CANNOT be used to access the HR service from the test pod?

web-service.default.pod

## 12. Which of the below name can be used to access the payroll service from the test application?
```bash
controlplane ~ ➜  k get pod -n payroll
NAME   READY   STATUS    RESTARTS   AGE
web    1/1     Running   0          17m

controlplane ~ ➜  k get svc -n payroll
NAME          TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE
web-service   ClusterIP   10.109.117.25   <none>        80/TCP    17m

controlplane ~ ➜  k describe svc web-service -n payroll
Name:              web-service
Namespace:         payroll
Labels:            <none>
Annotations:       <none>
Selector:          name=web
Type:              ClusterIP
IP Family Policy:  SingleStack
IP Families:       IPv4
IP:                10.109.117.25
IPs:               10.109.117.25
Port:              <unset>  80/TCP
TargetPort:        80/TCP
Endpoints:         10.244.0.5:80
Session Affinity:  None
Events:            <none>
```
web-service.payroll 
## 13. Which of the below name CANNOT be used to access the payroll service from the test application?

web-service.payroll.svc.cluster

## 14. We just deployed a web server - webapp - that accesses a database mysql - server. However the web server is failing to connect to the database server. Troubleshoot and fix the issue.

They could be in different namespaces. First locate the applications. The web server interface can be seen by clicking the tab Web Server at the top of your terminal.

- Web Server: webapp
- Uses the right DB_Host name
**Hint**: Set the ``DB_Hos``t environment variable to use ``mysql.payroll``.
```bash
controlplane ~ ➜  k get deploy 
NAME     READY   UP-TO-DATE   AVAILABLE   AGE
webapp   1/1     1            1           16s

```
Solution: Run the command: kubectl edit deploy webapp and correct the DB_Host value.

```bash

```

```yaml
    spec:
      containers:
      - env:
        - name: DB_Host
          value: mysql.payroll # mysql to mysql.payroll
        - name: DB_User
          value: root
        - name: DB_Password
          value: paswrd

```
## 15. From the hr pod nslookup the mysql service and redirect the output to a file /root/CKA/nslookup.out


```bash
controlplane ~ ➜  k exec hr -- nslookup

command terminated with exit code 1

controlplane ~ ✖ kubectl exec -it hr -- nslookup mysql.payroll > /root/CKA/nslookup.out

controlplane ~ ➜  kubectl exec -it hr -- nslookup mysql.payroll Server:         10.96.0.10
Address:        10.96.0.10#53

Name:   mysql.payroll.svc.cluster.local
Address: 10.101.208.151
```