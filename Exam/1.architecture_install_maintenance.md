## 1 SECTION: ARCHITECTURE, INSTALL AND MAINTENANCE
For this question, please set the context to cluster1 by running:

    kubectl config use-context cluster1

Create a service account called `pink-sa-cka24-arch`. Further create a cluster role called `pink-role-cka24-arch` with `full permissions` on all resources in the core api group under `default` namespace in `cluster1`.


Finally create a cluster role binding called `pink-role-binding-cka24-arch` to bind `pink-role-cka24-arch` cluster role with `pink-sa-cka24-arch` service account.

```bash
student-node ~ ➜ kubectl --context cluster1 create serviceaccount pink-sa-cka24-arch
student-node ~ ➜ kubectl --context cluster1 create clusterrole pink-role-cka24-arch --resource=* --verb=*
student-node ~ ➜ kubectl --context cluster1 create clusterrolebinding pink-role-binding-cka24-arch --clusterrole=pink-role-cka24-arch --serviceaccount=default:pink-sa-cka24-arch
```

## 2 SECTION: ARCHITECTURE, INSTALL AND MAINTENANCE

Find the node across all clusters that consumes the most CPU and store the result to the file `/opt/high_cpu_node` in the following format `cluster_name,node_name`.

The node could be in any clusters that are currently configured on the `student-node`.

Solution
Check out the metrics for all node across all clusters:

```bash
student-node ~ ➜  kubectl top node --context cluster1 --no-headers | sort -nr -k2 | head -1
cluster1-controlplane   127m   1%    703Mi   1%    

student-node ~ ➜  kubectl top node --context cluster2 --no-headers | sort -nr -k2 | head -1
cluster2-controlplane   126m   1%    675Mi   1%    

student-node ~ ➜  kubectl top node --context cluster3 --no-headers | sort -nr -k2 | head -1
cluster3-controlplane   577m   7%    1081Mi   1%    

student-node ~ ➜  kubectl top node --context cluster4 --no-headers | sort -nr -k2 | head -1
cluster4-controlplane   130m   1%    679Mi   1%    

```
Using this, find the node that uses most `cpu`. In this case, it is `cluster3-controlplane` on `cluster3`.


Save the result in the correct format to the file:
```bash
student-node ~ ➜  echo cluster3,cluster3-controlplane > /opt/high_cpu_node
```

## 3 SECTION: ARCHITECTURE, INSTALL AND MAINTENANCE

For this question, please set the context to cluster1 by running:

    kubectl config use-context cluster1

We have created a service account called `blue-sa-cka21-arch`, a cluster role called `blue-role-cka21-arch` and a cluster role binding called `blue-role-binding-cka21-arch`.


Update the permissions of this service account so that it can get the `pods` only in `default` namespace of `cluster1`.

Solution
Edit the blue-role-cka21-arch to update permissions:

```bash
student-node ~ ➜  kubectl edit clusterrole blue-role-cka21-arch --context cluster1
```
Under `rules:` -> `- apiGroups:` replace `apps` with `""`

`resources:` replace `- deployments` with `- pods` and save the changes.

You can verify it as below:
```bash
student-node ~ ➜  kubectl auth can-i get pods 
--as=system:serviceaccount:default:blue-sa-cka21-arch
yes

```

## 4 SECTION: ARCHITECTURE, INSTALL AND MAINTENANCE
For this question, please set the context to `cluster3` by running:

```bash
kubectl config use-context cluster3
```
A pod called `logger-cka03-arch` has been created in the default namespace. Inspect this pod and save ALL `INFO` and ERROR's to the file `/root/logger-cka03-arch-all` on the `student-node`.

Solution

Run the command `kubectl logs logger-cka03-arch --context cluster3 > /root/logger-cka03-arch-all` on the `student-node`.

Run the command :
```bash
student-node ~ ➜ kubectl logs logger-cka03-arch --context cluster3 > /root/logger-cka03-arch-all

student-node ~ ➜  head /root/logger-cka03-arch-all
INFO: Wed Oct 19 10:38:57 UTC 2022 Logger is running
ERROR: Wed Oct 19 10:38:57 UTC 2022 Logger encountered errors!
INFO: Wed Oct 19 10:38:57 UTC 2022 Logger is running
ERROR: Wed Oct 19 10:38:57 UTC 2022 Logger encountered errors!
INFO: Wed Oct 19 10:38:57 UTC 2022 Logger is running
ERROR: Wed Oct 19 10:38:57 UTC 2022 Logger encountered errors!
INFO: Wed Oct 19 10:38:57 UTC 2022 Logger is running
ERROR: Wed Oct 19 10:38:57 UTC 2022 Logger encountered errors!
INFO: Wed Oct 19 10:38:57 UTC 2022 Logger is running
ERROR: Wed Oct 19 10:38:57 UTC 2022 Logger encountered errors!

student-node ~ ➜  
```

## 5 SECTION: ARCHITECTURE, INSTALL AND MAINTENANCE

Find the node across all clusters that consumes the most `memory` and store the result to the file `/opt/high_memory_node` in the following format `cluster_name,node_name`.

The node could be in any clusters that are currently configured on the `student-node`.

Solution

```bash
student-node ~ ➜  kubectl top node --context cluster1 --no-headers | sort -nr -k4 | head -1
cluster1-controlplane   124m   1%    768Mi   1%    

student-node ~ ➜  kubectl top node --context cluster2 --no-headers | sort -nr -k4 | head -1
cluster2-controlplane   79m   0%    873Mi   1%    

student-node ~ ➜  kubectl top node --context cluster3 --no-headers | sort -nr -k4 | head -1
cluster3-controlplane   78m   0%    902Mi   1%  

student-node ~ ➜  kubectl top node --context cluster4 --no-headers | sort -nr -k4 | head -1
cluster4-controlplane   78m   0%    901Mi   1%    

student-node ~ ➜  
```
Using this, find the node that uses most memory. In this case, it is `cluster3-controlplane` on cluster3.


Save the result in the correct format to the file:
```bash
student-node ~ ➜  echo cluster3,cluster3-controlplane > /opt/high_memory_node 
```

## 6. For this question, please set the context to cluster1 by running:

kubectl config use-context cluster1

A pod named beta-pod-cka01-arch has been created in the beta-cka01-arch namespace. Inspect the logs and save all logs starting with the string ERROR in file /root/beta-pod-cka01-arch_errors on the student-node.

Solution: 

Run the below commands:
```bash
student-node ~ ➜  kubectl -n beta-cka01-arch logs beta-pod-cka01-arch --context cluster1 | grep ERROR > /root/beta-pod-cka01-arch_errors

student-node ~ ➜  head /root/beta-pod-cka01-arch_errors
ERROR: Sat Jul 23 02:49:28 UTC 2022 Logger encountered errors!
ERROR: Sat Jul 23 02:49:32 UTC 2022 Logger encountered errors!
ERROR: Sat Jul 23 02:49:36 UTC 2022 Logger encountered errors!
ERROR: Sat Jul 23 02:49:40 UTC 2022 Logger encountered errors!
ERROR: Sat Jul 23 02:49:44 UTC 2022 Logger encountered errors!
ERROR: Sat Jul 23 02:49:48 UTC 2022 Logger encountered errors!
ERROR: Sat Jul 23 02:49:52 UTC 2022 Logger encountered errors!
ERROR: Sat Jul 23 02:49:56 UTC 2022 Logger encountered errors!
ERROR: Sat Jul 23 02:50:00 UTC 2022 Logger encountered errors!
ERROR: Sat Jul 23 02:50:04 UTC 2022 Logger encountered errors!

student-node ~ ➜ 
```

## 7. SECTION: ARCHITECTURE, INSTALL AND MAINTENANCE
```bash
kubectl config use-context cluster3
```
Run a pod called ``alpine-sleeper-cka15-arch`` using the alpine image in the ``default`` namespace that will sleep for ``7200`` seconds.

Solution

Create the pod definition:
```bash
apiVersion: v1
kind: Pod
metadata:
  name: alpine-sleeper-cka15-arch
spec:
  containers:
  - name: alpine
    image: alpine
    command: ["/bin/sh", "-c", "sleep 7200"]
```
Create the pod:
```bash
student-node ~ ➜  kubectl apply -f alpine-sleeper-cka15-arch.yaml --context cluster3
```

```bash

```

```bash

```

```bash

```

```bash

```

```bash

```

```bash

```

```bash

```

```bash

```

```bash

```

```bash

```

```bash
```