
## 1. SECTION: STORAGE

For this question, please set the context to cluster1 by running:
```bash
kubectl config use-context cluster1
```
Create a storage class with the name banana-sc-cka08-str as per the properties given below:


- Provisioner should be kubernetes.io/no-provisioner,

- Volume binding mode should be WaitForFirstConsumer.

- Volume expansion should be enabled.

Solution: 

Create a yaml template as below:
```bash
kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: banana-sc-cka08-str
provisioner: kubernetes.io/no-provisioner
allowVolumeExpansion: true
volumeBindingMode: WaitForFirstConsumer

```
Apply the template:
```bash
kubectl apply -f <template-file-name>.yaml
```

## 2. SECTION: STORAGE

For this question, please set the context to cluster1 by running:

```bash
kubectl config use-context cluster1
```
There is a requirement to share a volume between two containers that are running within the same pod. Use the following instructions to create the pod and related objects:


- Create a pod named grape-pod-cka06-str.

- The main container should use the nginx image and mount a volume called grape-vol-cka06-str at path /var/log/nginx.

- The sidecar container can use busybox image, you might need to add a sleep command to this container to keep it running. Next, mount the same volume called grape-vol-cka06-str at the path /usr/src.

- The volume should be of type emptyDir.

Solution: 

Set context to cluster.

Create a yaml file as below:
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: grape-pod-cka06-str
spec:
  containers:
  - name: nginx
    image: nginx
    volumeMounts:
      - name: grape-vol-cka06-str
        mountPath: "/var/log/nginx"
  - name: busybox
    image: busybox
    command:
      - "bin/sh"
      - "-c"
      - "sleep 10000"
    volumeMounts:
      - name: grape-vol-cka06-str
        mountPath: "/usr/src"
  volumes:
  - name: grape-vol-cka06-str
    emptyDir: {}

```
Apply the template:
```bash
kubectl apply -f <template-file-name>.yaml
```

## 3. SECTION: STORAGE

There is a`` persistent volume`` named ``apple-pv-cka04-str``. Create a ``persistent volume`` claim named ``apple-pvc-cka04-str`` and request a 40Mi of storage from ``apple-pv-cka04-str`` PV.
The access mode should be ``ReadWriteOnce`` and storage class should be ``manual``.

Solution
Set context to cluster1:

**Create a yaml template as below:**
```bash
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: apple-pvc-cka04-str
spec:
  volumeName: apple-pv-cka04-str
  storageClassName: manual
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 40Mi
```
**Apply the template:**
```bash
kubectl apply -f <template-file-name>.yaml
```


## 4. SECTION: STORAGE

We want to deploy a python based application on the cluster using a template located at /root/olive-app-cka10-str.yaml on student-node. However, before you proceed we need to make some modifications to the YAML file as per details given below:


The YAML should also contain a persistent volume claim with name olive-pvc-cka10-str to claim a 100Mi of storage from olive-pv-cka10-str PV.


Update the deployment to add a sidecar container, which can use busybox image (you might need to add a sleep command for this container to keep it running.)

Share the python-data volume with this container and mount the same at path /usr/src. Make sure this container only has read permissions on this volume.


Finally, create a pod using this YAML and make sure the POD is in Running state.

Solution: 

Update olive-app-cka10-str.yaml template so that it looks like as below:
```yaml
---
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: olive-pvc-cka10-str
spec:
  accessModes:
  - ReadWriteMany
  storageClassName: olive-stc-cka10-str
  volumeName: olive-pv-cka10-str
  resources:
    requests:
      storage: 100Mi

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: olive-app-cka10-str
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: olive-app-cka10-str
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: kubernetes.io/hostname
                operator: In
                values:
                  - cluster1-node01
      containers:
      - name: python
        image: poroko/flask-demo-app
        ports:
        - containerPort: 5000
        volumeMounts:
        - name: python-data
          mountPath: /usr/share/
      - name: busybox
        image: busybox
        command:
          - "bin/sh"
          - "-c"
          - "sleep 10000"
        volumeMounts:
          - name: python-data
            mountPath: "/usr/src"
            readOnly: true
      volumes:
      - name: python-data
        persistentVolumeClaim:
          claimName: olive-pvc-cka10-str
  selector:
    matchLabels:
      app: olive-app-cka10-str

---
apiVersion: v1
kind: Service
metadata:
  name: olive-svc-cka10-str
spec:
  type: NodePort
  ports:
    - port: 5000
      nodePort: 32006
  selector:
    app: olive-app-cka10-str
```
Apply the template:
```bash
kubectl apply -f olive-app-cka10-str.yaml
```
## 4. SECTION: STORAGE

For this question, please set the context to cluster1 by running:
SECTION: STORAGE

For this question, please set the context to cluster1 by running:

There is a requirement to share a volume between two containers that are running within the same pod. Use the following instructions to create the pod and related objects:


- Create a pod named ``grape-pod-cka06-str``.

- The main container should use the nginx image and mount a volume called ``grape-vol-cka06-str ``at path ``/var/log/nginx``.

- The sidecar container can use ``busybox`` image, you might need to add a ``sleep`` command to this container to keep it running. Next, mount the same volume called ``grape-vol-cka06-str`` at the path ``/usr/src.``

- The volume should be of type ``emptyDir``.

Solution

Set context to ``cluster``.

**Create a yaml file as below:**

```bash
apiVersion: v1
kind: Pod
metadata:
  name: grape-pod-cka06-str
spec:
  containers:
  - name: nginx
    image: nginx
    volumeMounts:
      - name: grape-vol-cka06-str
        mountPath: "/var/log/nginx"
  - name: busybox
    image: busybox
    command:
      - "bin/sh"
      - "-c"
      - "sleep 10000"
    volumeMounts:
      - name: grape-vol-cka06-str
        mountPath: "/usr/src"
  volumes:
  - name: grape-vol-cka06-str
    emptyDir: {}
```
**Apply the template:**
```bash
kubectl apply -f <template-file-name>.yaml
```

## 6. SECTION: STORAGE

For this question, please set the context to cluster3 by running:

```bash
kubectl config use-context cluster3
```
A manifest file is available at the /root/app-wl03/ on the student-node node. There are some issues with the file; hence couldn't deploy a pod on the cluster3-controlplane node.

After fixing the issues, deploy the pod, and it should be in a running state.


NOTE: - Ensure that the existing limits are unchanged.

Solution: 

Set the correct context: -
```bash
kubectl config use-context cluster3
```
Use the cd command to move to the given directory: -
```bash
cd /root/app-wl03/
```
While creating the resource, you will see the error output as follows:
```bash
kubectl create -f app-wl03.yaml 
The Pod "app-wl03" is invalid: spec.containers[0].resources.requests: Invalid value: "1Gi": must be less than or equal to memory limit
```
In the spec.containers.resources.requests.memory value is not configured as compare to the memory limit.

As a fix, open the manifest file with the text editor such as vim or nano and set the value to 100Mi or less than 100Mi.

It should be look like as follows: -
```yaml
resources:
     requests:
       memory: 100Mi
     limits:
       memory: 100Mi
```
Final, create the resource from the kubectl create command: -
```bash
kubectl create -f app-wl03.yaml 
pod/app-wl03 created
```
## 7. SECTION: STORAGE

Create a new deployment called ocean-tv-wl09 in the default namespace using the image kodekloud/webapp-color:v1.
Use the following specs for the deployment:


1. Replica count should be 3.

2. Set the Max Unavailable to 40% and Max Surge to 55%.

3. Create the deployment and ensure all the pods are ready.

4. After successful deployment, upgrade the deployment image to kodekloud/webapp-color:v2 and inspect the deployment rollout status.

5. Check the rolling history of the deployment and on the student-node, save the current revision count number to the /opt/revision-count.txt file.

6. Finally, perform a rollback and revert back the deployment image to the older version.

Solution: 

Set the correct context: -
```bash
kubectl config use-context cluster1
```
Use the following template to create a deployment called ocean-tv-wl09: -

```yaml
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: ocean-tv-wl09
  name: ocean-tv-wl09
spec:
  replicas: 3
  selector:
    matchLabels:
      app: ocean-tv-wl09
  strategy: 
   type: RollingUpdate
   rollingUpdate:
     maxUnavailable: 40%
     maxSurge: 55%
  template:
    metadata:
      labels:
        app: ocean-tv-wl09
    spec:
      containers:
      - image: kodekloud/webapp-color:v1
        name: webapp-color
```
Now, create the deployment by using the kubectl create -f command in the default namespace: -
```bash
kubectl create -f <FILE-NAME>.yaml
```
After sometime, upgrade the deployment image to kodekloud/webapp-color:v2: -
```bash
kubectl set image deploy ocean-tv-wl09 webapp-color=kodekloud/webapp-color:v2
```
And check out the rollout history of the deployment ocean-tv-wl09:
```bash
kubectl rollout history deploy ocean-tv-wl09
deployment.apps/ocean-tv-wl09 
REVISION  CHANGE-CAUSE
1         <none>
2         <none>
```
NOTE: - Revision count is 2. In your lab, it could be different.



On the student-node, store the revision count to the given file: -
```bash
echo "2" > /opt/revision-count.txt
```
In final task, rollback the deployment image to an old version: -
```bash
kubectl rollout undo deployment ocean-tv-wl09
```
Verify the image name by using the following command: 
```bash
kubectl describe deploy ocean-tv-wl09
```
It should be kodekloud/webapp-color:v1 image.


## 8. SECTION: STORAGE

We have deployed a simple web application called frontend-wl04 on cluster1. This version of the application has some issues from a security point of view and needs to be updated to version 2.


Update the image and wait for the application to fully deploy.


You can verify the running application using the curl command on the terminal:
```bash
student-node ~ ➜  curl http://cluster1-node01:30080
<!doctype html>
<title>Hello from Flask</title>
<body style="background: #2980b9;"></body>
<div style="color: #e4e4e4;
    text-align:  center;
    height: 90px;
    vertical-align:  middle;">

  <h1>Hello from frontend-wl04-84fc69bd96-p7rbl!</h1>



  <h2>
    Application Version: v1
  </h2>


</div>
student-node ~ ➜ 
```
Version 2 Image details as follows:

1. Current version of the image is `v1`, we need to update with the image to kodekloud/webapp-color:v2.
2. Use the imperative command to update the image.

Solution: 

Now, test the current version of the application as follows:
```bash
student-node ~ ➜  curl http://cluster1-node01:30080
<!doctype html>
<title>Hello from Flask</title>
<body style="background: #2980b9;"></body>
<div style="color: #e4e4e4;
    text-align:  center;
    height: 90px;
    vertical-align:  middle;">

  <h1>Hello from frontend-wl04-84fc69bd96-p7rbl!</h1>



  <h2>
    Application Version: v1
  </h2>


</div>
student-node ~ ➜
```
Let's update the image, First, run the below command to check the existing image: 
```bash
kubectl get deploy frontend-wl04 -oyaml | grep -i image 
```
After checking the existing image, we have to use the imperative command (It will take less than a minute) to update the image: -
```bash
kubectl set image deploy frontend-wl04 simple-webapp=kodekloud/webapp-color:v2
```
Finally, run the below command to check the updated image: -
```bash
kubectl get deploy frontend-wl04 -oyaml | grep -i image 
```
It should be the kodekloud/webapp-color:v2 image and the same should be visible when you run the curl command again:
```bash
student-node ~ ➜  curl http://cluster1-node01:30080
<!doctype html>
<title>Hello from Flask</title>
<body style="background: #16a085;"></body>
<div style="color: #e4e4e4;
    text-align:  center;
    height: 90px;
    vertical-align:  middle;">

  <h1>Hello from frontend-wl04-6c54f479df-5tddd!</h1>



  <h2>
    Application Version: v2
  </h2>


</div>
```

## 8. SECTION: STORAGE

Create a ``persistent volume`` called ``data-pv-cka02-str`` with the below properties:


- Its capacity should be ``128Mi``.

- The volume type should be ``hostpath`` and path should be ``/opt/data-pv-cka02-str``.


Next, create a ``persistent volume claim`` called ``data-pvc-cka02-str`` as per below properties:


- Request ``50Mi`` of storage from ``data-pv-cka02-str`` PV.

Solution: 

Set context to cluster1:

**Create a yaml template as below:**
```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: data-pv-cka02-str
spec:
  capacity:
    storage: 128Mi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: /opt/data-pv-cka02-str
  storageClassName: manual

---

apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: data-pvc-cka02-str
spec:
  storageClassName: manual
  volumeName: data-pv-cka02-str
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 50Mi
```

**Apply the template:**
```bash
kubectl apply -f <template-file-name>.yaml
```

## 9. 
SECTION: STORAGE
Create a storage class called ``orange-stc-cka07-str`` as per the properties given below:


- Provisioner should be ``kubernetes.io/no-provisioner.``

- Volume binding mode should be ``WaitForFirstConsumer``.


Next, create a persistent volume called ``orange-pv-cka07-str`` as per the properties given below:


- Capacity should be ``150Mi``.

- Access mode should be ``ReadWriteOnce``.

- Reclaim policy should be ``Retain``.

- It should use storage class ``orange-stc-cka07-str``.

- Local path should be ``/opt/orange-data-cka07-st``r.

- Also add node affinity to create this value on ``cluster1-controlplane``.


Finally, create a persistent volume claim called ``orange-pvc-cka07-str`` as per the properties given below:


- Access mode should be ``ReadWriteOnce``.

- It should use storage class ``orange-stc-cka07-str``.

- Storage request should be ``128Mi``.

- The volume should be ``orange-pv-cka07-str``.

Solution: 

**Create a yaml file as below:**
```bash
kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: orange-stc-cka07-str
provisioner: kubernetes.io/no-provisioner
volumeBindingMode: WaitForFirstConsumer

---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: orange-pv-cka07-str
spec:
  capacity:
    storage: 150Mi
  accessModes:
  - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: orange-stc-cka07-str
  local:
    path: /opt/orange-data-cka07-str
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - cluster1-controlplane

---
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: orange-pvc-cka07-str
spec:
  accessModes:
  - ReadWriteOnce
  storageClassName: orange-stc-cka07-str
  volumeName: orange-pv-cka07-str
  resources:
    requests:
      storage: 128Mi
```
**Apply the template:**
```bash
kubectl apply -f <template-file-name>.yaml
```

```bash
```
```bash

```

```bash

```

```bash

```

```bash

```

```bash

```

```bash

```

```bash

```

```bash

```

```bash

```

```bash

```

```bash

```

```bash

```

```bash

```

```bash

```

```bash
```
```bash

```

```bash

```

```bash

```

```bash

```

```bash

```

```bash

```

```bash

```

```bash

```

```bash

```

```bash

```

```bash

```

```bash

```

```bash

```

```bash

```

```bash
```